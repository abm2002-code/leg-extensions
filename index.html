<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Leg Extensions Pose Detection</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
    <!-- Reference to GitHub-hosted stylesheet via jsDelivr CDN -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/abm2002-code/fitflex-styles@main/styles.css">
</head>
<body>
  <div class="container">
    <div class="app-header">
      <h1 class="app-title">FITFLEX</h1>
      <p class="app-subtitle">Leg Extensions Pose Detection</p>
    </div>
    
    <div class="video-container">
      <video id="video" autoplay playsinline></video>
      <canvas id="canvas"></canvas>
      <div id="warning"></div>
      <div id="debug"></div>
      <div class="angle-display">
        Knee Angle: <span id="knee-angle" class="angle-value">0°</span>
      </div>
    </div>
  </div>
  
  <audio id="audio" src="leg_raises.mp3" preload="auto"></audio>
    
  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const warningText = document.getElementById('warning');
    const debugText = document.getElementById('debug');
    const audio = document.getElementById('audio');
    const kneeAngleElement = document.getElementById('knee-angle');
    
    // Load the model (in a real implementation, you would load a trained model here)
    // For this demo, we'll use a simple threshold-based approach
    
    const pose = new Pose({ locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}` });
    pose.setOptions({ modelComplexity: 1, smoothLandmarks: true, minDetectionConfidence: 0.5, minTrackingConfidence: 0.5 });

    navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
        video.srcObject = stream;
        video.onloadedmetadata = () => {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
        };
    });

    function calculateAngle(a, b, c) {
        const ba = { x: a.x - b.x, y: a.y - b.y };
        const bc = { x: c.x - b.x, y: c.y - b.y };
        const dotProduct = ba.x * bc.x + ba.y * bc.y;
        const magnitudeBA = Math.sqrt(ba.x ** 2 + ba.y ** 2);
        const magnitudeBC = Math.sqrt(bc.x ** 2 + bc.y ** 2);
        const angle = Math.acos(dotProduct / (magnitudeBA * magnitudeBC)) * (180 / Math.PI);
        return angle;
    }

    pose.onResults(results => {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        if (results.poseLandmarks) {
            // Draw pose landmarks and connections
            drawConnectors(ctx, results.poseLandmarks, POSE_CONNECTIONS, { color: '#00FF7F', lineWidth: 4 });
            drawLandmarks(ctx, results.poseLandmarks, { color: '#FFFFFF', lineWidth: 2, radius: 6 });

            const landmarks = results.poseLandmarks;
            
            // Get relevant landmarks for right knee angle
            const rightHip = landmarks[24]; // RIGHT_HIP
            const rightKnee = landmarks[26]; // RIGHT_KNEE
            const rightAnkle = landmarks[28]; // RIGHT_ANKLE
            
            // Calculate knee angle for the right leg
            const kneeAngle = calculateAngle(rightHip, rightKnee, rightAnkle);
            
            // Update angle display
            kneeAngleElement.textContent = `${Math.round(kneeAngle)}°`;
            
            // Simple classification based on knee angle
            // In a real implementation, you would use the trained model here
            let classification = "correct";
            if (kneeAngle < 160) { // Example threshold
                classification = "incorrect";
            }
            
            // Play audio if the movement is classified as incorrect
            if (classification === "incorrect" && audio.paused) {
                warningText.innerText = "Incorrect Leg Extension Form!";
                audio.play();
            } else if (classification === "correct") {
                warningText.innerText = "";
            }
            
            // Debug information
            debugText.innerHTML = `Knee Angle: ${Math.round(kneeAngle)}°<br>Classification: ${classification}`;
        }
    });

    const camera = new Camera(video, {
        onFrame: async () => { await pose.send({ image: video }); },
        width: 640,
        height: 480
    });
    camera.start();
    
    // Handle window resize for responsiveness
    window.addEventListener('resize', () => {
        if (video.videoWidth > 0) {
            const containerWidth = document.querySelector('.video-container').clientWidth;
            const scale = containerWidth / video.videoWidth;
            // Maintain aspect ratio
            canvas.style.width = '100%';
            canvas.style.height = 'auto';
        }
    });
  </script>
</body>
</html>
